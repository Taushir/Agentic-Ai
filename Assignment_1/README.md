üáÆüá≥ Indian Sign Language Knowledge Assistant (Advanced RAG)

üìå Project Overview

Large Language Models (LLMs) often struggle with localized linguistic nuances, frequently misrepresenting Indian Sign Language (ISL) as a hand-based version of spoken languages such as Hindi or English. In reality, ISL is an independent, natural language with its own grammar, structure, and cultural context.

This project addresses these limitations by implementing an Advanced Retrieval-Augmented Generation (RAG) system.
The system is grounded in a curated knowledge base of 35 factual anchors covering ISL grammar, history, and linguistic identity. By retrieving authoritative content before generating responses, the model eliminates hallucinations and delivers factually grounded, context-aware answers related to Indian Sign Language and the Deaf community.

‚∏ª

üõ†Ô∏è Tools & Technologies Used

The project is designed for local execution in a Jupyter Notebook or Google Colab environment using the following AI stack:
	‚Ä¢	LangChain / LangChain-Community
Orchestration framework for document loading, vector storage, and retrieval pipelines.
	‚Ä¢	HuggingFace Transformers & HuggingFacePipeline
Used to run embedding and generation models locally on CPU/GPU.
	‚Ä¢	Sentence-Transformers (all-MiniLM-L6-v2)
Lightweight embedding model mapping text into a 384-dimensional dense vector space for semantic similarity.
	‚Ä¢	FAISS (Facebook AI Similarity Search)
High-performance vector database for efficient similarity search and retrieval.
	‚Ä¢	PyPDF
Used to extract and parse text from PDF-based knowledge sources.
	‚Ä¢	Google FLAN-T5-Large
Sequence-to-sequence language model used for answer generation based on retrieved context.

‚∏ª

üöÄ How to Run the Notebook

Follow the steps below to execute the project:

1Ô∏è‚É£ Environment Setup
	‚Ä¢	Use Google Colab or a local Jupyter Notebook
	‚Ä¢	Enable GPU runtime (optional but recommended)

2Ô∏è‚É£ Install Dependencies

Run the following command in the notebook:

pip install langchain langchain-community langchain-huggingface faiss-cpu sentence-transformers pypdf

3Ô∏è‚É£ Load Knowledge Base
	‚Ä¢	Upload your PDF knowledge source (e.g., SignLang_RAG.pdf)
	‚Ä¢	The PyPDFLoader automatically extracts text and metadata from the document

4Ô∏è‚É£ Text Chunking
	‚Ä¢	Uses RecursiveCharacterTextSplitter
	‚Ä¢	Chunk size: 400 characters
	‚Ä¢	Chunk overlap: 50 characters
This ensures contextual continuity across document splits.

5Ô∏è‚É£ Vectorization
	‚Ä¢	Generate embeddings using all-MiniLM-L6-v2
	‚Ä¢	Store vectors in a local FAISS index

6Ô∏è‚É£ Query the System

Use the following method to ask questions:

qa_chain.invoke(query)

	‚Ä¢	Retrieves the top 3 most relevant chunks
	‚Ä¢	Generates fact-grounded answers using FLAN-T5

‚∏ª

üéØ Key Features
	‚Ä¢	‚úÖ Fact-grounded responses (no hallucinations)
	‚Ä¢	‚úÖ Accurate representation of ISL as an independent language
	‚Ä¢	‚úÖ Efficient semantic search using FAISS
	‚Ä¢	‚úÖ Fully local execution (privacy-friendly)
	‚Ä¢	‚úÖ Scalable RAG architecture

‚∏ª

üîÆ Future Improvements

The current system provides a strong baseline. Planned enhancements include:
	‚Ä¢	Semantic Chunking
Replace fixed-size chunking with embedding-distance-based splitting for better contextual integrity.
	‚Ä¢	Neural Reranking
Two-stage retrieval:
	‚Ä¢	FAISS retrieves top-10 candidates
	‚Ä¢	Cross-Encoder reranker selects the most relevant context
	‚Ä¢	Metadata Filtering
Enable filtering by page number, chapter, or topic for targeted searches.
	‚Ä¢	Interactive UI
Integrate Gradio to provide a chat-based web interface for non-technical users.
	‚Ä¢	Hybrid Search
Combine semantic vector search with BM25 keyword search to improve accuracy for ISL-specific terminology and proper nouns.

‚∏ª

üìö Academic Relevance

This project demonstrates:
	‚Ä¢	Practical application of Retrieval-Augmented Generation
	‚Ä¢	Responsible AI by reducing hallucinations
	‚Ä¢	Language preservation through technology
	‚Ä¢	Accessibility-focused AI system design
